# ai/config/settings.py

import os
from openai import OpenAI 
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings
from langchain_pinecone import PineconeVectorStore
from pinecone import Pinecone

# -----------------------------
# üìÅ Í≤ΩÎ°ú ÏÑ§Ï†ï
# -----------------------------
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), "../.."))
PROMPT_DIR = os.path.join(BASE_DIR, "ai", "prompts")
UPLOAD_DIR = os.path.join(BASE_DIR, "ai", "uploads")
OUTPUT_DIR = os.path.join(BASE_DIR, "ai", "outputs")
ENV_PATH = os.path.join(BASE_DIR, "ai", ".env")

# -----------------------------
# üîê ÌôòÍ≤Ω Î≥ÄÏàò Î°úÎî©
# -----------------------------
load_dotenv(dotenv_path=ENV_PATH)
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
INDEX_NAME = "meeting-template-index"

# -----------------------------
# üîó Pinecone & ÏûÑÎ≤†Îî©
# -----------------------------
pc = Pinecone(api_key=PINECONE_API_KEY)
index = pc.Index(INDEX_NAME)
embedding_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
vectorstore = PineconeVectorStore(index=index, embedding=embedding_model, text_key="text")

template_image_path_map = {
    "basic_tem": os.path.join(UPLOAD_DIR, "basic_template.png")
}

vision_client = OpenAI(api_key=OPENAI_API_KEY)