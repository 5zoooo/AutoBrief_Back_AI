import os
import sys
import base64
from dotenv import load_dotenv

# ğŸ”§ sys.pathë¥¼ ê°€ì¥ ë¨¼ì € ì„¤ì •
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../..")))

from openai import OpenAI
from langchain_openai import OpenAIEmbeddings
from pinecone import Pinecone, ServerlessSpec
from ai.config import config  # âœ… ì´ì œ ë¬¸ì œ ì—†ìŒ

# 1. í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")

# 2. í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key=OPENAI_API_KEY)
embedding_model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
pc = Pinecone(api_key=PINECONE_API_KEY)

# 3. ì¸ë±ìŠ¤ ì„¤ì •
index_name = "vision-template-index"
if index_name not in pc.list_indexes().names():
    pc.create_index(
        name=index_name,
        dimension=1536,
        metric="cosine",
        spec=ServerlessSpec(cloud="aws", region="us-east-1")
    )
index = pc.Index(index_name)

# 4. ì´ë¯¸ì§€ í…œí”Œë¦¿ ì •ì˜
IMG_DIR = os.path.join(config.BASE_DIR, "ai", "images")
image_documents = [
    {"file": os.path.join(IMG_DIR, "basic_template.png"), "template_id": "basic_tem", "type": "template"},
]

# 5. GPT-Visionì„ í†µí•œ ì„¤ëª… ì¶”ì¶œ í•¨ìˆ˜
def describe_image_with_gpt_vision(image_path: str) -> str:
    with open(image_path, "rb") as f:
        image_bytes = f.read()
    base64_image = base64.b64encode(image_bytes).decode("utf-8")
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": "ì´ ì´ë¯¸ì§€ë¥¼ ë¬¸ì„œ í…œí”Œë¦¿ì˜ ë ˆì´ì•„ì›ƒê³¼ ëª©ì  ì¤‘ì‹¬ìœ¼ë¡œ ìì„¸íˆ ì„¤ëª…í•´ì¤˜."},
                    {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{base64_image}"}}
                ],
            }
        ],
        max_tokens=1000,
    )
    return response.choices[0].message.content

# 6. ì „ì²´ ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ì—…ë¡œë“œ
for doc in image_documents:
    print(f"ğŸ” GPT-Vision ì„¤ëª… ì¶”ì¶œ ì¤‘: {doc['file']}")
    description = describe_image_with_gpt_vision(doc["file"])
    print(f"âœ… ì„¤ëª… ê²°ê³¼: {description[:100]}...")

    print(f"ğŸ“¡ ì„ë² ë”© ë° ì—…ë¡œë“œ ì¤‘: {doc['template_id']}")
    vector = embedding_model.embed_query(description)
    index.upsert([{
        "id": doc["template_id"],
        "values": vector,
        "metadata": {
            "template_id": doc["template_id"],
            "type": doc["type"],
            "source": os.path.basename(doc["file"]),
            "description": description
        }
    }])

print("âœ… ì´ë¯¸ì§€ ê¸°ë°˜ ë²¡í„° DB êµ¬ì¶• ì™„ë£Œ")
